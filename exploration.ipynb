{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "import gzip\n",
    "from dataclasses import dataclass\n",
    "from functools import partial\n",
    "from os import listdir, path\n",
    "from typing import Callable, Optional, Tuple, Union\n",
    "\n",
    "import msgpack\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.axes import Axes\n",
    "from matplotlib.collections import PathCollection\n",
    "from matplotlib.figure import Figure\n",
    "from scipy import interpolate\n",
    "from scipy.optimize import curve_fit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STICKING_PROBABILITIES = [1.0, 0.8, 0.6, 0.4, 0.2, 0.1, 0.0]\n",
    "DATA_DIR = \"/run/media/life/barry/ViennaTools/spherical\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading Routines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some handy type definitions\n",
    "DataLoadingFunction = Callable[[str], dict]\n",
    "NumpyOrFloat = Union[float, np.ndarray]\n",
    "\n",
    "\n",
    "@dataclass(frozen=True, slots=True)\n",
    "class ThicknessData:\n",
    "    \"\"\"Container class for storing extracted layer thickness information\"\"\"\n",
    "\n",
    "    pos: np.ndarray\n",
    "    thickness: list[list[np.ndarray]]\n",
    "    sticking_probabilities: list[float]\n",
    "    max_times: list[int]\n",
    "    num_points: int\n",
    "\n",
    "\n",
    "def map_configs(fnames: list[str]) -> dict[str, list[str]]:\n",
    "    \"\"\"Takes a list of filenames and splits those into the geometry part as well as the\n",
    "    sticking probability part. For each geometry all thickness data resulting from\n",
    "    different sticking probabilities are stored in a list.\"\"\"\n",
    "    configs = {}\n",
    "    for fname in fnames:\n",
    "        sticking, geom = fname[:5], fname[6:]\n",
    "        if not geom in configs:\n",
    "            configs[geom] = []\n",
    "        configs[geom].append(sticking)\n",
    "    return configs\n",
    "\n",
    "\n",
    "def load_data(data_dir: str, filename: str) -> dict:\n",
    "    \"\"\"Loads nodal data of .msgpack.gz files storing graph data.\"\"\"\n",
    "    with gzip.open(path.join(data_dir, filename)) as gz:\n",
    "        data = msgpack.unpack(gz, use_list=False, raw=False)\n",
    "    return data[\"nodes\"]\n",
    "\n",
    "\n",
    "def extract_data(\n",
    "    loader: DataLoadingFunction,\n",
    "    name: str,\n",
    "    sticking: list[str],\n",
    "    prefix: str = \"extracted_\",\n",
    ") -> ThicknessData:\n",
    "    \"\"\"Uses the provided data loader to get the nodal data of a geometry and\n",
    "    subsequently extracts all fields starting with prefix.\"\"\"\n",
    "    data_list: list[list[np.ndarray]] = []\n",
    "    sticking_probabilities: list[float] = []\n",
    "    max_times: list[int] = []\n",
    "    num_points: list[int] = []\n",
    "    pos = np.array([])\n",
    "    for ps in sticking:\n",
    "        node_data = loader(f\"{ps}_{name}\")\n",
    "        labels = [s for s in node_data if s.startswith(prefix)]\n",
    "        data_list.append([np.array(node_data[l]) for l in labels])\n",
    "        sticking_probabilities.append(float(ps[1:]) / 1000)\n",
    "        max_times.append(len(labels))\n",
    "        num_points.extend([d.shape[0] for d in data_list[-1]])\n",
    "        if len(pos) == 0:\n",
    "            pos = np.array(node_data[\"pos\"])\n",
    "\n",
    "    # Ensure that the number of nodes is the same for all data\n",
    "    assert np.all(np.array(num_points) == num_points[0])\n",
    "\n",
    "    # Construct the data container instance\n",
    "    return ThicknessData(\n",
    "        thickness=data_list,\n",
    "        sticking_probabilities=sticking_probabilities,\n",
    "        max_times=max_times,\n",
    "        pos=pos,\n",
    "        num_points=num_points[0],\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Transformation and Augmentation Routines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_data_tensor(\n",
    "    thickness_data: ThicknessData,\n",
    "    sticking_probabilities: list[float],\n",
    ") -> np.ndarray:\n",
    "    \"\"\"Converts the `ThicknessData` instance to a numpy tensor with missing data\n",
    "    indicated by np.nan. First axis `point_index`, second axis `sticking_probability` and\n",
    "    third axis `time`.\"\"\"\n",
    "    max_time = 50\n",
    "    data_tensor = np.full(\n",
    "        (thickness_data.num_points, len(sticking_probabilities), max_time),\n",
    "        np.nan,\n",
    "    )\n",
    "    for i, s in enumerate(sticking_probabilities):\n",
    "        # First, determine the index\n",
    "        data_index = 0\n",
    "        for sp in thickness_data.sticking_probabilities:\n",
    "            if sp == s:\n",
    "                break\n",
    "            data_index = data_index + 1\n",
    "        else:\n",
    "            print(f\"Couldn't find data for sticking probability {s}\")\n",
    "            continue\n",
    "        data_tensor[:, i, 0] = 0\n",
    "        data_tensor[\n",
    "            :, i, 1 : np.min([thickness_data.max_times[data_index] + 1, max_time])\n",
    "        ] = np.array(thickness_data.thickness[data_index]).T\n",
    "    return data_tensor\n",
    "\n",
    "\n",
    "def fill_conformal(\n",
    "    data_tensor: np.ndarray, pos: np.ndarray, trench_diameter: float\n",
    ") -> np.ndarray:\n",
    "    \"\"\"Creates a new data array based on the provided data tensor that contains the\n",
    "    expected deposition radius for p_s=0 (conformal deposition).\"\"\"\n",
    "\n",
    "    expanded_data = data_tensor.copy()\n",
    "    y = np.where(pos[:, 1] > 0, pos[:, 1], 0)\n",
    "    time = np.arange(data_tensor.shape[2])\n",
    "\n",
    "    expanded_data[:, -1, :] = np.outer(\n",
    "        np.ones(data_tensor.shape[0]),\n",
    "        time,\n",
    "    )\n",
    "\n",
    "    expanded_data[:, -1, :] = expanded_data[:, -1, :] - np.outer(\n",
    "        y, np.ones(data_tensor.shape[2])\n",
    "    )\n",
    "\n",
    "    expanded_data[:, -1, :] = np.where(\n",
    "        expanded_data[:, -1, :] <= trench_diameter / 2,\n",
    "        expanded_data[:, -1, :],\n",
    "        trench_diameter / 2,\n",
    "    )\n",
    "    return expanded_data\n",
    "\n",
    "\n",
    "@dataclass(frozen=True, slots=True)\n",
    "class GridData:\n",
    "    xx: np.ndarray\n",
    "    yy: np.ndarray\n",
    "    zz: np.ndarray\n",
    "\n",
    "\n",
    "def to_grid_data(\n",
    "    z: np.ndarray,\n",
    "    sticking_probabilities: list[float],\n",
    ") -> GridData:\n",
    "    \"\"\"Converts the provided data to a format compatible with matplotlib's meshgrid used\n",
    "    by surface plots.\"\"\"\n",
    "    y = sticking_probabilities\n",
    "    x = np.arange(z.shape[1])\n",
    "    xx, yy = np.meshgrid(x, y)\n",
    "    # Ensure that all values are >= 0\n",
    "    zz = np.where(z >= 0, z, np.nan)\n",
    "    return GridData(xx, yy, zz)\n",
    "\n",
    "\n",
    "def fill_along_axis(\n",
    "    grid_data: GridData,\n",
    "    masking_function: Callable[[np.ndarray], np.ndarray],\n",
    "    axis: int = 0,\n",
    ") -> GridData:\n",
    "    \"\"\"Fills griddata values for elements where `masking_function`\n",
    "    evaluates to True using (linear) interpolation along one axis.\"\"\"\n",
    "    z = grid_data.zz.copy()\n",
    "    mask = masking_function(z)\n",
    "    for (sequence, ma) in zip(np.moveaxis(z, 0, axis), np.moveaxis(mask, 0, axis)):\n",
    "        if ma.sum() != 0 and (~ma).sum():\n",
    "            sequence[ma] = np.interp(\n",
    "                np.flatnonzero(ma), np.flatnonzero(~ma), sequence[~ma]\n",
    "            )\n",
    "    return GridData(grid_data.xx, grid_data.yy, z)\n",
    "\n",
    "\n",
    "def interpolate_data(\n",
    "    grid_data: GridData,\n",
    "    sticking_probabilities: list,\n",
    "    resolution: int = 100,\n",
    ") -> GridData:\n",
    "    \"\"\"Linearly interpolates the provided grid data.\"\"\"\n",
    "    xnew = np.linspace(0, grid_data.zz.shape[1], resolution)\n",
    "    ynew = np.linspace(\n",
    "        np.min(sticking_probabilities),\n",
    "        np.max(sticking_probabilities),\n",
    "        resolution,\n",
    "    )\n",
    "    xxnew, yynew = np.meshgrid(xnew, ynew)\n",
    "\n",
    "    zznew = interpolate.griddata(\n",
    "        (grid_data.xx.ravel(), grid_data.yy.ravel()),\n",
    "        grid_data.zz.ravel(),\n",
    "        (xxnew.ravel(), yynew.ravel()),\n",
    "        method=\"linear\",\n",
    "    ).reshape(xxnew.shape)\n",
    "\n",
    "    return GridData(xxnew, yynew, zznew)\n",
    "\n",
    "\n",
    "def check_monotonic(\n",
    "    x: np.ndarray,\n",
    "    axis: int = 0,\n",
    "    eps: float = 0.1,\n",
    "    increasing: bool = True,\n",
    "):\n",
    "    \"\"\"Checks if the provided array is monotonically increasing or decreasing along the\n",
    "    provided axis\"\"\"\n",
    "    assert axis < len(x.shape)\n",
    "    if increasing:\n",
    "        monotonic = np.diff(x, 1, axis=axis, prepend=0) > -eps\n",
    "    else:\n",
    "        monotonic = np.diff(x, 1, axis=axis, append=0) > eps\n",
    "    return monotonic\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualization Routines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data_2d(\n",
    "    mapped: np.ndarray,\n",
    "    sticking_probabilities: list[float],\n",
    "    point_index: int,\n",
    "    normalize: bool = False,\n",
    "    log: bool = False,\n",
    ") -> Tuple[Figure, Axes]:\n",
    "    \"\"\"Creates two 2D plots which show the relation of the deposition radius with\n",
    "    respect to the time dimension as well as the sticking probability\"\"\"\n",
    "    plt.close(\"all\")\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=2, squeeze=False, figsize=(10, 4))\n",
    "    cmap = plt.get_cmap(\"viridis\", mapped.shape[2])\n",
    "    for i, r in enumerate(np.moveaxis(mapped[point_index, :, :], 0, 1)):\n",
    "        if normalize:\n",
    "            r = np.where(r != 0, r, np.nan)\n",
    "            ax[0, 0].plot(\n",
    "                sticking_probabilities,\n",
    "                r / (i + 1),\n",
    "                marker=\"x\",\n",
    "                color=cmap(i),\n",
    "            )\n",
    "        else:\n",
    "            ax[0, 0].plot(\n",
    "                sticking_probabilities,\n",
    "                r,\n",
    "                marker=\"x\",\n",
    "                color=cmap(i),\n",
    "            )\n",
    "\n",
    "    # Invert the x-axis so that we start with a sticking probability of 1 at the left\n",
    "    ax[0, 0].invert_xaxis()\n",
    "\n",
    "    for i, r in enumerate(np.moveaxis(mapped[point_index, :, :], 0, 0)):\n",
    "        if normalize:\n",
    "            r = np.where(r != 0, r, np.nan)\n",
    "            ax[0, 1].plot(\n",
    "                r / (1 + np.arange(49)),\n",
    "                marker=\"x\",\n",
    "                label=sticking_probabilities[i],\n",
    "            )\n",
    "        else:\n",
    "            ax[0, 1].plot(\n",
    "                r,\n",
    "                marker=\"x\",\n",
    "                label=sticking_probabilities[i],\n",
    "            )\n",
    "\n",
    "    ax[0, 0].grid(which=\"both\")\n",
    "    ax[0, 0].set_xlabel(\"sticking probability\")\n",
    "    ax[0, 0].set_ylabel(\"radius\")\n",
    "    ax[0, 1].set_xlabel(\"time\")\n",
    "    ax[0, 1].set_ylabel(\"radius\")\n",
    "    ax[0, 1].grid(which=\"both\")\n",
    "\n",
    "    if log:\n",
    "        ax[0, 0].set_yscale(\"log\")\n",
    "        ax[0, 1].set_yscale(\"log\")\n",
    "    ax[0, 1].legend()\n",
    "    return fig, ax\n",
    "\n",
    "\n",
    "def draw_3d_plot(\n",
    "    ax: Axes,\n",
    "    data: np.ndarray,\n",
    "    sticking_probabilities: list[float],\n",
    "    interp: bool = False,\n",
    "    fill: bool = False,\n",
    "    monotonic: bool = False,\n",
    ") -> None:\n",
    "    \"\"\"Creates a 3D surface plot of the data in the provided plot axes object.\"\"\"\n",
    "    ax.clear()\n",
    "    grid_data = to_grid_data(data, sticking_probabilities)\n",
    "    cmap = plt.get_cmap(\"coolwarm\")\n",
    "    if fill:\n",
    "        grid_data = fill_along_axis(grid_data, np.isnan, 0)\n",
    "        if monotonic:\n",
    "            grid_data = fill_along_axis(\n",
    "                grid_data, lambda x: ~check_monotonic(x, axis=0), axis=1\n",
    "            )\n",
    "\n",
    "    if interp:\n",
    "        grid_data = interpolate_data(grid_data, sticking_probabilities, resolution=100)\n",
    "\n",
    "    ax.plot_surface(\n",
    "        grid_data.xx,\n",
    "        grid_data.yy,\n",
    "        grid_data.zz,\n",
    "        linewidth=1,\n",
    "        cmap=cmap,\n",
    "        antialiased=True,\n",
    "    )\n",
    "\n",
    "    ax.set_xlabel(\"time\")\n",
    "    ax.set_ylabel(\"sticking probability\")\n",
    "    ax.set_zlabel(\"radius\")\n",
    "\n",
    "\n",
    "def plot_data_3d(\n",
    "    pos: np.ndarray,\n",
    "    data_tensor: np.ndarray,\n",
    "    sticking_probabilities: list[float],\n",
    "    interp: bool = False,\n",
    "    fill: bool = False,\n",
    "    monotonic: bool = False,\n",
    "    figsize: Tuple[float, float] = (10, 5),\n",
    "    selection_callback: Optional[Callable[[int, Axes], None]] = None,\n",
    ") -> Tuple[Figure, Axes]:\n",
    "    \"\"\"Plots the geometry and also creates a 3D surface plot of the data corresponding\n",
    "    to the selected surface point.\"\"\"\n",
    "\n",
    "    plt.close(\"all\")\n",
    "\n",
    "    point_index = 0\n",
    "\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    ax_selector = fig.add_subplot(121)\n",
    "    ax_3d = fig.add_subplot(122, projection=\"3d\")\n",
    "    fig.subplots_adjust(hspace=0.4)\n",
    "\n",
    "    draw_3d_plot(\n",
    "        ax_3d,\n",
    "        data_tensor[point_index, :, :],\n",
    "        sticking_probabilities,\n",
    "        interp,\n",
    "        fill,\n",
    "        monotonic,\n",
    "    )\n",
    "\n",
    "    if selection_callback:\n",
    "        selection_callback(point_index, ax_3d)\n",
    "\n",
    "    ax_selector.set_title(\"Geometry\\n(selected: 0)\")\n",
    "    ax_selector.scatter(\n",
    "        pos[:, 0],\n",
    "        pos[:, 1],\n",
    "        color=\"black\",\n",
    "        linewidths=0,\n",
    "        marker=\".\",\n",
    "        picker=True,\n",
    "        pickradius=0.2,\n",
    "    )\n",
    "\n",
    "    scat = ax_selector.scatter(\n",
    "        pos[point_index, 0], pos[point_index, 1], color=\"red\", marker=\"o\"\n",
    "    )\n",
    "\n",
    "    def onpick(event):\n",
    "        if isinstance(event.artist, PathCollection):\n",
    "            point_index = event.ind[0]\n",
    "            colors = np.zeros((len(pos), 3))\n",
    "            colors[point_index, 0] = 1\n",
    "            scat.set_offsets((pos[point_index, 0], pos[point_index, 1]))\n",
    "            ax_selector.set_title(f\"Geometry\\n(selected: {point_index})\")\n",
    "\n",
    "            # Now redraw 3d plot\n",
    "            draw_3d_plot(\n",
    "                ax_3d,\n",
    "                data_tensor[point_index, :, :],\n",
    "                sticking_probabilities,\n",
    "                interp,\n",
    "                fill,\n",
    "                monotonic,\n",
    "                # fit_function,\n",
    "            )\n",
    "\n",
    "            if selection_callback:\n",
    "                selection_callback(point_index, ax_3d)\n",
    "\n",
    "            fig.canvas.draw_idle()\n",
    "\n",
    "    ax_selector.axis(\"scaled\")\n",
    "    fig.canvas.mpl_connect(\"pick_event\", onpick)\n",
    "    return fig, ax_3d\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and Transforming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all available configurations\n",
    "fnames = listdir(DATA_DIR)\n",
    "configs = list(map_configs(fnames).items())\n",
    "\n",
    "# Select a particular geometry\n",
    "geometry_index = 13  # 57\n",
    "name, sticking = configs[geometry_index]\n",
    "\n",
    "print(name)\n",
    "trench_diameter = float(name.split(\"_\")[0][1:4])\n",
    "\n",
    "# Load the data of this geometry\n",
    "data_loader = partial(load_data, DATA_DIR)\n",
    "\n",
    "# Load the spherical distribution data (extracted from physical simulations)\n",
    "extracted = extract_data(data_loader, name, sticking)\n",
    "data = to_data_tensor(\n",
    "    extracted,\n",
    "    STICKING_PROBABILITIES,\n",
    ")\n",
    "\n",
    "# Load the viewfactor data\n",
    "viewfactor_data = to_data_tensor(\n",
    "    extract_data(data_loader, name, [\"s1000\"], prefix=\"viewfactor_\"),\n",
    "    STICKING_PROBABILITIES,\n",
    ")\n",
    "\n",
    "# Deviation of the simulation from the viewfactor model\n",
    "deviation_data = np.zeros_like(data)\n",
    "for i in range(data.shape[1]):\n",
    "    deviation_data[:, i, :] = data[:, i, :] - viewfactor_data[:, 0, :]\n",
    "\n",
    "# Extend data with expected conformal thickness at p_s=0\n",
    "expanded_data = fill_conformal(data, extracted.pos, trench_diameter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_pipeline(pipeline: list, data: np.ndarray) -> np.ndarray:\n",
    "    for f, args in pipeline:\n",
    "        data = f(*args)\n",
    "    return data\n",
    "\n",
    "\n",
    "pipeline = [\n",
    "    (fill_along_axis, (np.isnan, 0)),  # Fill NaN\n",
    "    (\n",
    "        fill_along_axis,\n",
    "        (lambda x: ~check_monotonic(x, axis=0), 1),\n",
    "    ),  # Ensure that data is monotonic\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nearest neighbors extracted data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_index = 300\n",
    "fig, _ = plot_data_2d(\n",
    "    data,\n",
    "    STICKING_PROBABILITIES,\n",
    "    point_index=point_index,\n",
    "    normalize=False,\n",
    "    log=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Viewfactor data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, _ = plot_data_2d(\n",
    "    viewfactor_data,\n",
    "    STICKING_PROBABILITIES,\n",
    "    point_index=point_index,\n",
    "    normalize=False,\n",
    "    log=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deviational data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, _ = plot_data_2d(\n",
    "    deviation_data,\n",
    "    STICKING_PROBABILITIES,\n",
    "    point_index=point_index,\n",
    "    normalize=False,\n",
    "    log=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extended data (+ conformal thickness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, _ = plot_data_2d(\n",
    "    expanded_data,\n",
    "    STICKING_PROBABILITIES,\n",
    "    point_index=point_index,\n",
    "    normalize=False,\n",
    "    log=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3D Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_data_3d(\n",
    "    extracted.pos,\n",
    "    data,\n",
    "    STICKING_PROBABILITIES,\n",
    "    interp=False,\n",
    "    fill=True,\n",
    "    monotonic=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extended dataset (+conformal deposition thickness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_data_3d(\n",
    "    extracted.pos,\n",
    "    expanded_data,\n",
    "    STICKING_PROBABILITIES,\n",
    "    interp=False,\n",
    "    fill=True,\n",
    "    monotonic=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Curve Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(\n",
    "    data: np.ndarray,\n",
    "    pos: np.ndarray,\n",
    "    sticking_probabilities: list[float],\n",
    "    test_function: Callable,\n",
    ") -> None:\n",
    "    def fit_surface(\n",
    "        x: np.ndarray,\n",
    "        y: np.ndarray,\n",
    "        a: float,\n",
    "        b: float,\n",
    "        c: float,\n",
    "        d: float,\n",
    "        e: float,\n",
    "        f: float,\n",
    "        g: float,\n",
    "    ) -> np.ndarray:\n",
    "        \"\"\"x: time, y: sp\"\"\"\n",
    "        t = test_function((x, y), a, b, c, d, e, f, g)\n",
    "        return t\n",
    "\n",
    "    def callback(point_index: int, ax: Axes) -> None:\n",
    "        grid_data = to_grid_data(data[point_index, :, :], sticking_probabilities)\n",
    "        grid_data = fill_along_axis(grid_data, np.isnan, axis=0)\n",
    "        grid_data = fill_along_axis(\n",
    "            grid_data, lambda x: ~check_monotonic(x, axis=0), axis=1\n",
    "        )\n",
    "\n",
    "        popt, pcov = curve_fit(\n",
    "            test_function,\n",
    "            (grid_data.xx.ravel(), grid_data.yy.ravel()),\n",
    "            grid_data.zz.ravel(),\n",
    "        )\n",
    "        print(popt)\n",
    "\n",
    "        xnew = np.linspace(0, grid_data.zz.shape[1], 100)\n",
    "        ynew = np.linspace(\n",
    "            np.min(sticking_probabilities), np.max(sticking_probabilities), 100\n",
    "        )\n",
    "        xxnew, yynew = np.meshgrid(xnew, ynew)\n",
    "        zznew = fit_surface(xxnew.ravel(), yynew.ravel(), *popt)\n",
    "        ax.plot_surface(\n",
    "            xxnew,\n",
    "            yynew,\n",
    "            zznew.reshape(xxnew.shape),\n",
    "            linewidth=1,\n",
    "            antialiased=True,\n",
    "        )\n",
    "\n",
    "    plot_data_3d(\n",
    "        pos,\n",
    "        data,\n",
    "        sticking_probabilities,\n",
    "        interp=False,\n",
    "        fill=True,\n",
    "        monotonic=True,\n",
    "        selection_callback=callback,\n",
    "    )\n",
    "\n",
    "\n",
    "def fun(\n",
    "    X: Union[np.ndarray, Tuple[np.ndarray, np.ndarray]],\n",
    "    a: float,\n",
    "    b: float,\n",
    "    c: float,\n",
    "    d: float,\n",
    "    e: float,\n",
    "    f: float,\n",
    "    g: float,\n",
    ") -> np.ndarray:\n",
    "    # Normalize and reshape the inputs\n",
    "    x = X[0]  # / 50\n",
    "    y = 1 - X[1]\n",
    "\n",
    "    return a * np.tanh(b * x * (c + d * y)) * (e + f * y**2 + g * y**4)\n",
    "\n",
    "\n",
    "optimize(expanded_data, extracted.pos, STICKING_PROBABILITIES, fun)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

