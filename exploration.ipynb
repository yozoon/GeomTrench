{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "import gzip\n",
    "import os\n",
    "from dataclasses import dataclass\n",
    "from functools import partial\n",
    "from os import listdir, path\n",
    "from typing import Any, Callable, List, Optional, Tuple, Union\n",
    "\n",
    "import msgpack\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "from matplotlib import gridspec\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.axes import Axes\n",
    "from matplotlib.collections import PathCollection\n",
    "from matplotlib.figure import Figure\n",
    "from mpl_toolkits.mplot3d.axes3d import Axes3D\n",
    "from scipy import interpolate\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "_ = load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STICKING_PROBABILITIES = [1.0, 0.8, 0.6, 0.4, 0.2, 0.1, 0.0]\n",
    "DATA_DIR = os.environ[\"DATA_DIR\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading Routines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some handy type definitions\n",
    "DataLoadingFunction = Callable[[str], dict]\n",
    "NumpyOrFloat = Union[float, np.ndarray]\n",
    "\n",
    "\n",
    "@dataclass(frozen=True, slots=True)\n",
    "class ThicknessData:\n",
    "    \"\"\"Container class for storing extracted layer thickness information\"\"\"\n",
    "\n",
    "    pos: np.ndarray\n",
    "    thickness: list[list[np.ndarray]]\n",
    "    sticking_probabilities: list[float]\n",
    "    max_times: list[int]\n",
    "    num_points: int\n",
    "\n",
    "\n",
    "def map_configs(fnames: list[str]) -> dict[str, list[str]]:\n",
    "    \"\"\"Takes a list of filenames and splits those into the geometry part as well as the\n",
    "    sticking probability part. For each geometry all thickness data resulting from\n",
    "    different sticking probabilities are stored in a list.\"\"\"\n",
    "    configs = {}\n",
    "    for fname in fnames:\n",
    "        sticking, geom = fname[:5], fname[6:]\n",
    "        if not geom in configs:\n",
    "            configs[geom] = []\n",
    "        configs[geom].append(sticking)\n",
    "    return configs\n",
    "\n",
    "\n",
    "def load_data(data_dir: str, filename: str) -> dict:\n",
    "    \"\"\"Loads nodal data of .msgpack.gz files storing graph data.\"\"\"\n",
    "    with gzip.open(path.join(data_dir, filename)) as gz:\n",
    "        data = msgpack.unpack(gz, use_list=False, raw=False)\n",
    "    return data[\"nodes\"]\n",
    "\n",
    "\n",
    "def extract_data(\n",
    "    loader: DataLoadingFunction,\n",
    "    name: str,\n",
    "    sticking: list[str],\n",
    "    prefix: str = \"extracted_\",\n",
    ") -> ThicknessData:\n",
    "    \"\"\"Uses the provided data loader to get the nodal data of a geometry and\n",
    "    subsequently extracts all fields starting with prefix.\"\"\"\n",
    "    data_list: list[list[np.ndarray]] = []\n",
    "    sticking_probabilities: list[float] = []\n",
    "    max_times: list[int] = []\n",
    "    num_points: list[int] = []\n",
    "    pos = np.array([])\n",
    "    for ps in sticking:\n",
    "        node_data = loader(f\"{ps}_{name}\")\n",
    "        labels = [s for s in node_data if s.startswith(prefix)]\n",
    "        data_list.append([np.array(node_data[l]) for l in labels])\n",
    "        sticking_probabilities.append(float(ps[1:]) / 1000)\n",
    "        max_times.append(len(labels))\n",
    "        num_points.extend([d.shape[0] for d in data_list[-1]])\n",
    "        if len(pos) == 0:\n",
    "            pos = np.array(node_data[\"pos\"])\n",
    "\n",
    "    # Ensure that the number of nodes is the same for all data\n",
    "    assert np.all(np.array(num_points) == num_points[0])\n",
    "\n",
    "    # Construct the data container instance\n",
    "    return ThicknessData(\n",
    "        thickness=data_list,\n",
    "        sticking_probabilities=sticking_probabilities,\n",
    "        max_times=max_times,\n",
    "        pos=pos,\n",
    "        num_points=num_points[0],\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Transformation and Augmentation Routines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_data_tensor(\n",
    "    thickness_data: ThicknessData,\n",
    "    sticking_probabilities: list[float],\n",
    ") -> np.ndarray:\n",
    "    \"\"\"Converts the `ThicknessData` instance to a numpy tensor with missing data\n",
    "    indicated by np.nan. First axis `point_index`, second axis `sticking_probability` and\n",
    "    third axis `time`.\"\"\"\n",
    "    max_time = 50\n",
    "    data_tensor = np.full(\n",
    "        (thickness_data.num_points, len(sticking_probabilities), max_time),\n",
    "        np.nan,\n",
    "    )\n",
    "    for i, s in enumerate(sticking_probabilities):\n",
    "        # First, determine the index\n",
    "        data_index = 0\n",
    "        for sp in thickness_data.sticking_probabilities:\n",
    "            if sp == s:\n",
    "                break\n",
    "            data_index = data_index + 1\n",
    "        else:\n",
    "            print(f\"Couldn't find data for sticking probability {s}\")\n",
    "            continue\n",
    "        data_tensor[:, i, 0] = 0\n",
    "        data_tensor[\n",
    "            :, i, 1 : np.min([thickness_data.max_times[data_index] + 1, max_time])\n",
    "        ] = np.array(thickness_data.thickness[data_index]).T\n",
    "    return data_tensor\n",
    "\n",
    "\n",
    "def fill_conformal(\n",
    "    data_tensor: np.ndarray, pos: np.ndarray, trench_diameter: float\n",
    ") -> np.ndarray:\n",
    "    \"\"\"Creates a new data array based on the provided data tensor that contains the\n",
    "    expected deposition radius for p_s=0 (conformal deposition).\"\"\"\n",
    "\n",
    "    expanded_data = data_tensor.copy()\n",
    "    y = np.where(pos[:, 1] > 0, pos[:, 1], 0)\n",
    "    time = np.arange(data_tensor.shape[2])\n",
    "\n",
    "    expanded_data[:, -1, :] = np.outer(\n",
    "        np.ones(data_tensor.shape[0]),\n",
    "        time,\n",
    "    )\n",
    "\n",
    "    expanded_data[:, -1, :] = expanded_data[:, -1, :] - np.outer(\n",
    "        y, np.ones(data_tensor.shape[2])\n",
    "    )\n",
    "\n",
    "    expanded_data[:, -1, :] = np.where(\n",
    "        expanded_data[:, -1, :] <= trench_diameter / 2,\n",
    "        expanded_data[:, -1, :],\n",
    "        trench_diameter / 2,\n",
    "    )\n",
    "    expanded_data[:, -1, :] = np.where(\n",
    "        expanded_data[:, -1, :] < 0, 0, expanded_data[:, -1, :]\n",
    "    )\n",
    "    return expanded_data\n",
    "\n",
    "\n",
    "def mask_monotonic(\n",
    "    x: np.ndarray,\n",
    "    axis: int = 0,\n",
    "    eps: float = 0.1,\n",
    "    increasing: bool = True,\n",
    "    iterations: int = 1,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"Checks if the provided array is monotonically increasing or decreasing along the\n",
    "    provided axis\"\"\"\n",
    "    assert axis < len(x.shape)\n",
    "    monotonic = np.full_like(x, True, dtype=bool)\n",
    "    for i in np.arange(1, iterations + 1):\n",
    "        if increasing:\n",
    "            monotonic = monotonic & (\n",
    "                np.diff(x, i, axis=axis, prepend=np.zeros((i, x.shape[1]))) > -eps\n",
    "            )\n",
    "        else:\n",
    "            monotonic = monotonic & (\n",
    "                np.diff(x, i, axis=axis, append=np.zeros((i, x.shape[1]))) > eps\n",
    "            )\n",
    "    return monotonic\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid data operations (pipeline building blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(frozen=True, slots=True)\n",
    "class GridData:\n",
    "    time: np.ndarray\n",
    "    sp: np.ndarray\n",
    "    radius: np.ndarray\n",
    "\n",
    "\n",
    "def to_grid_data(\n",
    "    z: np.ndarray,\n",
    "    sticking_probabilities: List[float],\n",
    ") -> GridData:\n",
    "    \"\"\"Converts the provided data to a format compatible with matplotlib's meshgrid used\n",
    "    by surface plots.\"\"\"\n",
    "    y = sticking_probabilities\n",
    "    x = np.arange(z.shape[1])\n",
    "    xx, yy = np.meshgrid(x, y)\n",
    "    # Ensure that all values are >= 0\n",
    "    zz = np.where(z >= 0, z, np.nan)\n",
    "    return GridData(xx, yy, zz)\n",
    "\n",
    "\n",
    "def fill_along_axis(\n",
    "    grid_data: GridData,\n",
    "    masking_function: Callable[[np.ndarray], np.ndarray],\n",
    "    axis: int = 0,\n",
    ") -> GridData:\n",
    "    \"\"\"Fills griddata values for elements where `masking_function`\n",
    "    evaluates to True using (linear) interpolation along one axis.\"\"\"\n",
    "    z = grid_data.radius.copy()\n",
    "    mask = masking_function(z)\n",
    "    for (sequence, ma) in zip(np.moveaxis(z, 0, axis), np.moveaxis(mask, 0, axis)):\n",
    "        if ma.sum() != 0 and (~ma).sum():\n",
    "            sequence[ma] = np.interp(\n",
    "                np.flatnonzero(ma), np.flatnonzero(~ma), sequence[~ma]\n",
    "            )\n",
    "    return GridData(grid_data.time, grid_data.sp, z)\n",
    "\n",
    "\n",
    "def interpolate_data(\n",
    "    grid_data: GridData,\n",
    "    resolution: int = 100,\n",
    ") -> GridData:\n",
    "    \"\"\"Linearly interpolates the provided grid data.\"\"\"\n",
    "    xnew = np.linspace(\n",
    "        np.min(grid_data.time[0, :]),\n",
    "        np.max(grid_data.time[0, :]),\n",
    "        resolution,\n",
    "    )\n",
    "    ynew = np.linspace(\n",
    "        np.min(grid_data.sp[:, 0]),\n",
    "        np.max(grid_data.sp[:, 0]),\n",
    "        resolution,\n",
    "    )\n",
    "    xxnew, yynew = np.meshgrid(xnew, ynew)\n",
    "\n",
    "    zznew = interpolate.griddata(\n",
    "        (grid_data.time.ravel(), grid_data.sp.ravel()),\n",
    "        grid_data.radius.ravel(),\n",
    "        (xxnew.ravel(), yynew.ravel()),\n",
    "        method=\"linear\",\n",
    "    ).reshape(xxnew.shape)\n",
    "\n",
    "    return GridData(xxnew, yynew, zznew)\n",
    "\n",
    "\n",
    "def mask_closed(\n",
    "    grid_data: GridData,\n",
    "    trench_diameter: float,\n",
    ") -> GridData:\n",
    "    closed = 2 * grid_data.time / (1 + grid_data.sp) > trench_diameter\n",
    "    return GridData(\n",
    "        grid_data.time, grid_data.sp, np.where(closed, np.nan, grid_data.radius)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualization Routines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_2d_plot(ax: list[Axes], grid_data: GridData, _: int) -> None:\n",
    "    \"\"\"Creates two 2D plots which show the relation of the deposition radius with\n",
    "    respect to the time dimension as well as the sticking probability\"\"\"\n",
    "    assert len(ax) >= 2\n",
    "\n",
    "    # Plot 1: radius vs sticking probability\n",
    "    ax[0].clear()\n",
    "    n_timesteps = grid_data.radius.shape[1]\n",
    "    cmap = plt.get_cmap(\"viridis\", n_timesteps)\n",
    "    for i in np.arange(n_timesteps):\n",
    "        x = grid_data.sp[:, i]\n",
    "        y = grid_data.radius[:, i]\n",
    "        ax[0].plot(\n",
    "            x,\n",
    "            y,\n",
    "            marker=\"x\",\n",
    "            color=cmap(i),\n",
    "        )\n",
    "\n",
    "    ax[0].invert_xaxis()\n",
    "    ax[0].grid(which=\"both\")\n",
    "    ax[0].set_xlabel(\"sticking probability\")\n",
    "    ax[0].set_ylabel(\"radius\")\n",
    "\n",
    "    # Plot 2: radius vs time\n",
    "    ax[1].clear()\n",
    "    n_sticking_probabilities = grid_data.radius.shape[0]\n",
    "    for i in np.arange(n_sticking_probabilities):\n",
    "        x = grid_data.time[i, :]\n",
    "        y = grid_data.radius[i, :]\n",
    "        ax[1].plot(\n",
    "            x,\n",
    "            y,\n",
    "            marker=\"x\",\n",
    "            label=str(grid_data.sp[i, 0]),\n",
    "        )\n",
    "\n",
    "    ax[1].grid(which=\"both\")\n",
    "    ax[1].set_xlabel(\"time\")\n",
    "    ax[1].set_ylabel(\"radius\")\n",
    "    ax[1].legend()\n",
    "\n",
    "\n",
    "def draw_3d_plot(ax: list[Axes], grid_data: GridData, _: int) -> None:\n",
    "    \"\"\"Creates a 3D surface plot of the data in the provided plot axes object.\"\"\"\n",
    "    assert len(ax) > 0\n",
    "\n",
    "    ax[0].clear()\n",
    "    cmap = plt.get_cmap(\"coolwarm\")\n",
    "\n",
    "    ax[0].plot_surface(\n",
    "        grid_data.time,\n",
    "        grid_data.sp,\n",
    "        grid_data.radius,\n",
    "        linewidth=1,\n",
    "        cmap=cmap,\n",
    "        antialiased=True,\n",
    "    )\n",
    "\n",
    "    ax[0].set_xlabel(\"time\")\n",
    "    ax[0].set_ylabel(\"sticking probability\")\n",
    "    ax[0].set_zlabel(\"radius\")\n",
    "\n",
    "\n",
    "def apply_pipeline(\n",
    "    pipeline: list[Tuple[Callable[[GridData, Any], GridData], Any]],\n",
    "    grid_data: GridData,\n",
    ") -> GridData:\n",
    "    \"\"\"Applies the provided pipeline to the grid_data instance.\"\"\"\n",
    "    for op, args in pipeline:\n",
    "        grid_data = op(grid_data, *args)\n",
    "    return grid_data\n",
    "\n",
    "\n",
    "def selector_plot(\n",
    "    pos: np.ndarray,\n",
    "    data_tensor: np.ndarray,\n",
    "    sticking_probabilities: List[float],\n",
    "    pipeline: Optional[List[Tuple[Callable[[GridData, Any], GridData], Any]]] = None,\n",
    "    selection_callback: Optional[Callable[[List[Axes], GridData, int], None]] = None,\n",
    "    figsize: Tuple[float, float] = (10, 5),\n",
    "    projection: Optional[str] = None,\n",
    "    num_subplots: int = 1,\n",
    "    initial_point_index: int = 0,\n",
    ") -> Tuple[Figure, List[Axes]]:\n",
    "    \"\"\"Plots the geometry and also creates a 3D surface plot of the data corresponding\n",
    "    to the selected surface point.\"\"\"\n",
    "\n",
    "    plt.close(\"all\")\n",
    "\n",
    "    point_index = initial_point_index\n",
    "\n",
    "    # Create a figure\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "\n",
    "    # Create two subplots, one for the selector, one for the data plot(s)\n",
    "    gs = gridspec.GridSpec(1, num_subplots + 1, figure=fig)\n",
    "    ax_selector = fig.add_subplot(gs[0, 0])\n",
    "    ax_plot = []\n",
    "    for i in range(num_subplots):\n",
    "        ax_plot.append(fig.add_subplot(gs[0, i + 1], projection=projection))\n",
    "    fig.subplots_adjust(hspace=0.4)\n",
    "\n",
    "    # Convert to grid data and apply the pipeline, if it exists\n",
    "    grid_data = to_grid_data(data_tensor[point_index, ...], sticking_probabilities)\n",
    "    if pipeline:\n",
    "        grid_data = apply_pipeline(pipeline, grid_data)\n",
    "\n",
    "    # Call the selection callback, if it exists\n",
    "    if selection_callback:\n",
    "        selection_callback(ax_plot, grid_data, point_index)\n",
    "\n",
    "    # Plot the geometry in the picker subplot\n",
    "    ax_selector.set_title(\"Geometry\\n(selected: 0)\")\n",
    "    ax_selector.axhline(0, linestyle=\"--\", color=\"black\", linewidth=1)\n",
    "    ax_selector.axvline(0, linestyle=\"--\", color=\"black\", linewidth=1)\n",
    "    ax_selector.scatter(\n",
    "        pos[:, 0],\n",
    "        pos[:, 1],\n",
    "        color=\"black\",\n",
    "        linewidths=0,\n",
    "        marker=\".\",\n",
    "        picker=True,\n",
    "        pickradius=0.2,\n",
    "    )\n",
    "\n",
    "    # Plot the currently selected point in the picker subplot\n",
    "    scat = ax_selector.scatter(\n",
    "        pos[point_index, 0], pos[point_index, 1], color=\"red\", marker=\"o\"\n",
    "    )\n",
    "\n",
    "    def onpick(event):\n",
    "        # If we detected a click on the ax_selector scatterplot\n",
    "        if isinstance(event.artist, PathCollection):\n",
    "            point_index = event.ind[0]\n",
    "            colors = np.zeros((len(pos), 3))\n",
    "            colors[point_index, 0] = 1\n",
    "            scat.set_offsets((pos[point_index, 0], pos[point_index, 1]))\n",
    "            ax_selector.set_title(f\"Geometry\\n(selected: {point_index})\")\n",
    "\n",
    "            grid_data = to_grid_data(\n",
    "                data_tensor[point_index, ...], sticking_probabilities\n",
    "            )\n",
    "\n",
    "            if pipeline:\n",
    "                grid_data = apply_pipeline(pipeline, grid_data)\n",
    "\n",
    "            if selection_callback:\n",
    "                selection_callback(ax_plot, grid_data, point_index)\n",
    "\n",
    "            fig.canvas.draw_idle()\n",
    "\n",
    "    ax_selector.axis(\"scaled\")\n",
    "    fig.canvas.mpl_connect(\"pick_event\", onpick)\n",
    "    return fig, ax_plot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and Transforming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all available configurations\n",
    "fnames = listdir(DATA_DIR)\n",
    "configs = list(map_configs(fnames).items())\n",
    "\n",
    "# Select a particular geometry\n",
    "geometry_index = 27 # 34 #np.random.randint(0, len(configs)) #57 #13\n",
    "print(geometry_index)\n",
    "name, sticking = configs[geometry_index]\n",
    "\n",
    "print(name)\n",
    "trench_diameter = float(name.split(\"_\")[0][1:4])\n",
    "\n",
    "# Load the data of this geometry\n",
    "data_loader = partial(load_data, DATA_DIR)\n",
    "\n",
    "# Load the spherical distribution data (extracted from physical simulations)\n",
    "thickness_data = extract_data(data_loader, name, sticking)\n",
    "data = to_data_tensor(\n",
    "    thickness_data,\n",
    "    STICKING_PROBABILITIES,\n",
    ")\n",
    "\n",
    "# Load the viewfactor data\n",
    "viewfactor_data = to_data_tensor(\n",
    "    extract_data(data_loader, name, [\"s1000\"], prefix=\"viewfactor_\"),\n",
    "    STICKING_PROBABILITIES,\n",
    ")\n",
    "\n",
    "# Deviation of the simulation from the viewfactor model\n",
    "deviation_data = np.zeros_like(data)\n",
    "for i in range(data.shape[1]):\n",
    "    deviation_data[:, i, :] = data[:, i, :] - viewfactor_data[:, 0, :]\n",
    "\n",
    "# Use the radius calculated with the viewfactor method instead of the extracted one\n",
    "data[:, 0, :] = viewfactor_data[:, 0, :]\n",
    "\n",
    "# Extend data with expected conformal thickness at p_s=0\n",
    "extended_data = fill_conformal(data, thickness_data.pos, trench_diameter)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data transformation pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = [\n",
    "    (  # Fill NaN\n",
    "        fill_along_axis,\n",
    "        (np.isnan, 0),\n",
    "    ),\n",
    "    (  # Ensure that data is monotonic\n",
    "        fill_along_axis,\n",
    "        (lambda x: ~mask_monotonic(x, axis=0), 1),\n",
    "    ),\n",
    "    # (  # Interpolation\n",
    "    #     interpolate_data,\n",
    "    #     (100,),\n",
    "    # ),\n",
    "    # (  # mask off closed configurations\n",
    "    #     mask_closed,\n",
    "    #     (trench_diameter,),\n",
    "    # ),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = selector_plot(\n",
    "    thickness_data.pos,\n",
    "    extended_data,\n",
    "    STICKING_PROBABILITIES,\n",
    "    pipeline=pipeline,\n",
    "    selection_callback=draw_2d_plot,\n",
    "    num_subplots=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3D Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = selector_plot(\n",
    "    thickness_data.pos,\n",
    "    data,\n",
    "    STICKING_PROBABILITIES,\n",
    "    pipeline=pipeline,\n",
    "    selection_callback=draw_3d_plot,\n",
    "    projection=\"3d\",\n",
    "    num_subplots=1,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extended dataset (+conformal deposition thickness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = selector_plot(\n",
    "    thickness_data.pos,\n",
    "    extended_data,\n",
    "    STICKING_PROBABILITIES,\n",
    "    pipeline=pipeline,\n",
    "    selection_callback=draw_3d_plot,\n",
    "    projection=\"3d\",\n",
    "    initial_point_index=777,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Curve Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing(data_tensor, sticking_probabilities, point_index):\n",
    "    data = data_tensor[point_index, ...]\n",
    "    grid_data = to_grid_data(data, sticking_probabilities)\n",
    "    grid_data = fill_along_axis(grid_data, np.isnan, 0)\n",
    "    grid_data = fill_along_axis(\n",
    "        grid_data, lambda x: ~mask_monotonic(x, axis=0), axis=1\n",
    "    )\n",
    "    ydata = grid_data.radius.T[-1]\n",
    "\n",
    "    # def fit_fn(x, a, b, c, d, e):\n",
    "    #     return a * b ** (-c * x) - d * x + e\n",
    "\n",
    "    def fit_fn(ps, a, b, c, d):\n",
    "        return a * np.exp(-b * ps) - c * ps + d\n",
    "\n",
    "    popt, pcov = curve_fit(\n",
    "        fit_fn, sticking_probabilities, ydata\n",
    "    )  # , bounds=([1e-2, 1e-2, 1e-2, 0], [10,10,10,10]))\n",
    "    print(popt, pcov)\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1)\n",
    "    ax.plot(sticking_probabilities, ydata, marker=\"x\")\n",
    "    x = np.linspace(0, 1, 100)\n",
    "    plt.plot(x, fit_fn(x, *popt))\n",
    "    # ax.invert_xaxis()\n",
    "    ax.grid(which=\"both\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "testing(extended_data, STICKING_PROBABILITIES, 681)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(\n",
    "    data: np.ndarray,\n",
    "    pos: np.ndarray,\n",
    "    sticking_probabilities: list[float],\n",
    "    tf: Callable,\n",
    "    diff: bool = False,\n",
    ") -> None:\n",
    "    def callback(ax: List[Axes3D], grid_data: GridData, point_index: int) -> None:\n",
    "        ax[0].clear()\n",
    "        X = np.vstack([grid_data.time.ravel(), grid_data.sp.ravel()])\n",
    "        Y = grid_data.radius.ravel()\n",
    "        # valid = ~np.isnan(Y)\n",
    "        valid = np.full_like(Y, True, dtype=bool)\n",
    "        success = False\n",
    "        # test_function = lambda x, a, b, c, d, e, f: tf(point_index, x, a, b, c, d, e, f)\n",
    "        test_function = lambda x, a, b: tf(point_index, x, a, b)\n",
    "        try:\n",
    "            popt, pcov = curve_fit(\n",
    "                test_function,\n",
    "                X[:, valid],\n",
    "                Y[valid],\n",
    "                maxfev=2000,\n",
    "                bounds=([1e-3, 0.5], [30, 1.5]),\n",
    "            )\n",
    "            success = True\n",
    "        except RuntimeError as e:\n",
    "            print(e)\n",
    "            popt = []\n",
    "\n",
    "        if not diff:\n",
    "            # First, draw the actual surface\n",
    "            draw_3d_plot(ax, grid_data, point_index)\n",
    "\n",
    "        if success:\n",
    "            zznew = test_function(X, *popt).reshape(grid_data.radius.shape)\n",
    "            mse = np.sum((grid_data.radius - zznew) ** 2) / np.count_nonzero(\n",
    "                np.isreal(zznew)\n",
    "            )\n",
    "            print(f\"Parameters: {popt}, MSE: {mse}\")\n",
    "            if diff:\n",
    "                ax[0].plot_surface(\n",
    "                    grid_data.time,\n",
    "                    grid_data.sp,\n",
    "                    grid_data.radius - zznew,\n",
    "                    linewidth=1,\n",
    "                    antialiased=True,\n",
    "                )\n",
    "            else:\n",
    "                # Then draw the fitted surface\n",
    "                xnew = np.linspace(0, grid_data.time.shape[1], 100)\n",
    "                ynew = np.linspace(\n",
    "                    np.min(sticking_probabilities), np.max(sticking_probabilities), 100\n",
    "                )\n",
    "                xxnew, yynew = np.meshgrid(xnew, ynew)\n",
    "                zznew = test_function((xxnew.ravel(), yynew.ravel()), *popt).reshape(\n",
    "                    xxnew.shape\n",
    "                )\n",
    "                ax[0].plot_surface(\n",
    "                    xxnew,\n",
    "                    yynew,\n",
    "                    zznew,\n",
    "                    linewidth=1,\n",
    "                    antialiased=True,\n",
    "                )\n",
    "\n",
    "    selector_plot(\n",
    "        pos,\n",
    "        data,\n",
    "        sticking_probabilities,\n",
    "        pipeline=pipeline,\n",
    "        selection_callback=callback,\n",
    "        projection=\"3d\",\n",
    "    )\n",
    "\n",
    "\n",
    "def fit_function(X, a, b, c, d, e, f):\n",
    "    t, s = X\n",
    "    return (a * np.exp(-b * s) - c * s + d) * np.tanh((e * (1 - s) + f) * t)\n",
    "\n",
    "\n",
    "def fit_function_2(point_index, X, a, b, c, d, e, f):\n",
    "    t, s = X\n",
    "    # y = t + g\n",
    "    # y = np.where(y > trench_diameter, trench_diameter, y)\n",
    "    # y = np.where(y < 0, 0, y)\n",
    "    ypos = thickness_data.pos[point_index, 1]\n",
    "    y = t - ypos\n",
    "    y = np.where(y > trench_diameter / 2, trench_diameter / 2, y)\n",
    "    y = np.where(y < 0, 0, y)\n",
    "    y2 = (a * np.exp(-b * s) - c * s + d) * np.tanh((e * (1 - s) + f) * t)\n",
    "    return np.min([y, y2], axis=0)\n",
    "\n",
    "\n",
    "def fit_function_3(point_index, X, a, b):\n",
    "    t, s = X\n",
    "\n",
    "    # Calculated viewfactor thickness\n",
    "    vf = extended_data[point_index, 0, :]\n",
    "    f = interp1d(np.arange(len(vf)), vf, fill_value=\"extrapolate\")\n",
    "    vf = f(t)\n",
    "\n",
    "    # Expected conformal layer thickenss\n",
    "    ypos = thickness_data.pos[point_index, 1]\n",
    "    co = t - np.max([0, ypos])\n",
    "    co = np.where(co > trench_diameter / 2, trench_diameter / 2, co)\n",
    "    co = np.where(co < 0, 0, co)\n",
    "\n",
    "    def blend(s):\n",
    "        return s ** (1 / a)\n",
    "\n",
    "    return blend(s) * vf + (1 - blend(s)) * co\n",
    "\n",
    "\n",
    "optimize(\n",
    "    extended_data,\n",
    "    thickness_data.pos,\n",
    "    STICKING_PROBABILITIES,\n",
    "    fit_function_3,\n",
    "    False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testplot(diff: bool = False) -> None:\n",
    "    def ftest2(X, point_index):\n",
    "        t, s = X\n",
    "\n",
    "        # Calculated viewfactor thickness\n",
    "        vf = extended_data[point_index, 0, :]\n",
    "\n",
    "        # Expected conformal layer thickenss\n",
    "        ypos = thickness_data.pos[point_index, 1]\n",
    "        co = t - np.max([0, ypos])\n",
    "        co = np.where(co > trench_diameter / 2, trench_diameter / 2, co)\n",
    "        co = np.where(co < 0, 0, co)\n",
    "\n",
    "        def blend(s):\n",
    "            return s ** (1 / 8)\n",
    "\n",
    "        return blend(s) * vf + (1 - blend(s)) * co\n",
    "\n",
    "    def callback(ax: List[Axes3D], grid_data: GridData, point_index: int) -> None:\n",
    "        ax[0].clear()\n",
    "\n",
    "        z = ftest2((grid_data.time, grid_data.sp), point_index)\n",
    "        if diff:\n",
    "            ax[0].plot_surface(\n",
    "                grid_data.time,\n",
    "                grid_data.sp,\n",
    "                grid_data.radius - z,\n",
    "                linewidth=1,\n",
    "                antialiased=True,\n",
    "            )\n",
    "        else:\n",
    "            draw_3d_plot(ax, grid_data, point_index)\n",
    "\n",
    "            ax[0].plot_surface(\n",
    "                grid_data.time,\n",
    "                grid_data.sp,\n",
    "                z,\n",
    "                linewidth=1,\n",
    "                antialiased=True,\n",
    "            )\n",
    "\n",
    "    selector_plot(\n",
    "        thickness_data.pos,\n",
    "        extended_data,\n",
    "        STICKING_PROBABILITIES,\n",
    "        pipeline=pipeline,\n",
    "        selection_callback=callback,\n",
    "        projection=\"3d\",\n",
    "        initial_point_index=279,\n",
    "    )\n",
    "\n",
    "\n",
    "testplot(diff=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
