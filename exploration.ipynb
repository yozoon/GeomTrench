{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "import gzip\n",
    "from dataclasses import dataclass\n",
    "from functools import partial\n",
    "from os import listdir, path\n",
    "from typing import Callable, Optional, Tuple, Union\n",
    "\n",
    "import msgpack\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.axes import Axes\n",
    "from matplotlib.collections import PathCollection\n",
    "from matplotlib.figure import Figure\n",
    "from scipy import interpolate\n",
    "from scipy.optimize import curve_fit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STICKING_PROBABILITIES = [1.0, 0.8, 0.6, 0.4, 0.2, 0.1]\n",
    "DATA_DIR = \"/run/media/life/barry/ViennaTools/spherical\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading Routines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some handy type definitions\n",
    "DataLoadingFunction = Callable[[str], dict]\n",
    "NumpyOrFloat = Union[float, np.ndarray]\n",
    "\n",
    "\n",
    "@dataclass(frozen=True, slots=True)\n",
    "class ThicknessData:\n",
    "    \"\"\"Container class for storing extracted layer thickness information\"\"\"\n",
    "\n",
    "    pos: np.ndarray\n",
    "    thickness: list[list[np.ndarray]]\n",
    "    sticking_probabilities: list[float]\n",
    "    max_times: list[int]\n",
    "    num_points: int\n",
    "\n",
    "\n",
    "def map_configs(fnames: list[str]) -> dict[str, list[str]]:\n",
    "    \"\"\"Takes a list of filenames and splits those into the geometry part as well as the\n",
    "    sticking probability part. For each geometry all thickness data resulting from\n",
    "    different sticking probabilities are stored in a list.\"\"\"\n",
    "    configs = {}\n",
    "    for fname in fnames:\n",
    "        sticking, geom = fname[:5], fname[6:]\n",
    "        if not geom in configs:\n",
    "            configs[geom] = []\n",
    "        configs[geom].append(sticking)\n",
    "    return configs\n",
    "\n",
    "\n",
    "def load_data(data_dir: str, filename: str) -> dict:\n",
    "    \"\"\"Loads nodal data of .msgpack.gz files storing graph data.\"\"\"\n",
    "    with gzip.open(path.join(data_dir, filename)) as gz:\n",
    "        data = msgpack.unpack(gz, use_list=False, raw=False)\n",
    "    return data[\"nodes\"]\n",
    "\n",
    "\n",
    "def extract_data(\n",
    "    loader: DataLoadingFunction,\n",
    "    name: str,\n",
    "    sticking: list[str],\n",
    "    prefix: str = \"extracted_\",\n",
    ") -> ThicknessData:\n",
    "    \"\"\"Uses the provided data loader to get the nodal data of a geometry and\n",
    "    subsequently extracts all fields starting with prefix.\"\"\"\n",
    "    data_list: list[list[np.ndarray]] = []\n",
    "    sticking_probabilities: list[float] = []\n",
    "    max_times: list[int] = []\n",
    "    num_points: list[int] = []\n",
    "    pos = []\n",
    "    for ps in sticking:\n",
    "        node_data = loader(f\"{ps}_{name}\")\n",
    "        labels = [s for s in node_data if s.startswith(prefix)]\n",
    "        data_list.append([np.array(node_data[l]) for l in labels])\n",
    "        sticking_probabilities.append(float(ps[1:]) / 1000)\n",
    "        max_times.append(len(labels))\n",
    "        num_points.extend([d.shape[0] for d in data_list[-1]])\n",
    "        if len(pos) == 0:\n",
    "            pos = np.array(node_data[\"pos\"])\n",
    "\n",
    "    \n",
    "\n",
    "    # Ensure that the number of nodes is the same for all data\n",
    "    assert np.all(np.array(num_points) == num_points[0])\n",
    "\n",
    "    # Construct the data container instance\n",
    "    return ThicknessData(\n",
    "        thickness=data_list,\n",
    "        sticking_probabilities=sticking_probabilities,\n",
    "        max_times=max_times,\n",
    "        pos=pos,\n",
    "        num_points=num_points[0],\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Transformation Routines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_data_tensor(\n",
    "    data: ThicknessData,\n",
    "    sticking_probabilities: list[float],\n",
    ") -> np.ndarray:\n",
    "    \"\"\"Converts the `ThicknessData` instance to a numpy tensor with missing data\n",
    "    indicated by np.nan. First axis `point_index`, second axis `sticking_probability` and\n",
    "    third axis `time`.\"\"\"\n",
    "    max_time = 50\n",
    "    mapped = np.full(\n",
    "        (data.num_points, len(sticking_probabilities), max_time),\n",
    "        np.nan,\n",
    "    )\n",
    "    for i, s in enumerate(sticking_probabilities):\n",
    "        # First, determine the index\n",
    "        data_index = 0\n",
    "        for sp in data.sticking_probabilities:\n",
    "            if sp == s:\n",
    "                break\n",
    "            data_index = data_index + 1\n",
    "        else:\n",
    "            print(f\"Couldn't find data for sticking probability {s}\")\n",
    "            continue\n",
    "        mapped[:, i, 0] = 0\n",
    "        mapped[:, i, 1 : np.min([data.max_times[data_index] + 1, max_time])] = np.array(\n",
    "            data.thickness[data_index]\n",
    "        ).T\n",
    "    return mapped\n",
    "\n",
    "\n",
    "def to_grid_data(\n",
    "    z: np.ndarray,\n",
    "    sticking_probabilities: list[float],\n",
    ") -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "    \"\"\"Converts the provided data to a format compatible with matplotlib's meshgrid used\n",
    "    by surface plots.\"\"\"\n",
    "    y = sticking_probabilities\n",
    "    x = np.arange(z.shape[1])\n",
    "    xx, yy = np.meshgrid(x, y)\n",
    "    # Ensure that all values are >= 0\n",
    "    zz = np.where(z >= 0, z, np.nan)\n",
    "    return xx, yy, zz\n",
    "\n",
    "\n",
    "def fill_along_axis(\n",
    "    x: np.ndarray,\n",
    "    mask: np.ndarray,\n",
    "    axis: int = 0,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"Fills values of multidimensional array where mask is True using\n",
    "    (linear) interpolation along one axis.\"\"\"\n",
    "    x = x.copy()\n",
    "    for (sequence, ma) in zip(np.moveaxis(x, 0, axis), np.moveaxis(mask, 0, axis)):\n",
    "        if ma.sum() != 0 and (~ma).sum():\n",
    "            sequence[ma] = np.interp(\n",
    "                np.flatnonzero(ma), np.flatnonzero(~ma), sequence[~ma]\n",
    "            )\n",
    "    return x\n",
    "\n",
    "\n",
    "def check_monotonic(\n",
    "    x: np.ndarray,\n",
    "    axis: int = 0,\n",
    "    eps: float = 0.1,\n",
    "    increasing: bool = True,\n",
    "):\n",
    "    \"\"\"Checks if the provided array is monotonically increasing or decreasing along the\n",
    "    provided axis\"\"\"\n",
    "    assert axis < len(x.shape)\n",
    "    if increasing:\n",
    "        monotonic = np.diff(x, 1, axis=axis, prepend=0) > -eps\n",
    "    else:\n",
    "        monotonic = np.diff(x, 1, axis=axis, append=0) > eps\n",
    "    return monotonic\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualization Routines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data_2d(\n",
    "    mapped: np.ndarray,\n",
    "    sticking_probabilities: list[float],\n",
    "    point_index: int,\n",
    "    normalize: bool = False,\n",
    "    log: bool = False,\n",
    ") -> Tuple[Figure, Axes]:\n",
    "    \"\"\"Creates two 2D plots which show the relation of the deposition radius with\n",
    "    respect to the time dimension as well as the sticking probability\"\"\"\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=2, squeeze=False, figsize=(10, 4))\n",
    "    cmap = plt.get_cmap(\"viridis\", mapped.shape[2])\n",
    "    for i, r in enumerate(np.moveaxis(mapped[point_index, :, :], 0, 1)):\n",
    "        if normalize:\n",
    "            r = np.where(r != 0, r, np.nan)\n",
    "            ax[0, 0].plot(\n",
    "                sticking_probabilities,\n",
    "                r / (i + 1),\n",
    "                marker=\"x\",\n",
    "                color=cmap(i),\n",
    "            )\n",
    "        else:\n",
    "            ax[0, 0].plot(\n",
    "                sticking_probabilities,\n",
    "                r,\n",
    "                marker=\"x\",\n",
    "                color=cmap(i),\n",
    "            )\n",
    "\n",
    "    # Invert the x-axis so that we start with a sticking probability of 1 at the left\n",
    "    ax[0, 0].invert_xaxis()\n",
    "\n",
    "    for i, r in enumerate(np.moveaxis(mapped[point_index, :, :], 0, 0)):\n",
    "        if normalize:\n",
    "            r = np.where(r != 0, r, np.nan)\n",
    "            ax[0, 1].plot(\n",
    "                r / (1 + np.arange(49)),\n",
    "                marker=\"x\",\n",
    "                label=sticking_probabilities[i],\n",
    "            )\n",
    "        else:\n",
    "            ax[0, 1].plot(\n",
    "                r,\n",
    "                marker=\"x\",\n",
    "                label=sticking_probabilities[i],\n",
    "            )\n",
    "\n",
    "    ax[0, 0].grid(which=\"both\")\n",
    "    ax[0, 0].set_xlabel(\"sticking probability\")\n",
    "    ax[0, 0].set_ylabel(\"radius\")\n",
    "    ax[0, 1].set_xlabel(\"time\")\n",
    "    ax[0, 1].set_ylabel(\"radius\")\n",
    "    ax[0, 1].grid(which=\"both\")\n",
    "\n",
    "    if log:\n",
    "        ax[0, 0].set_yscale(\"log\")\n",
    "        ax[0, 1].set_yscale(\"log\")\n",
    "    ax[0, 1].legend()\n",
    "    return fig, ax\n",
    "\n",
    "\n",
    "def draw_3d_plot(\n",
    "    ax: Axes,\n",
    "    data: np.ndarray,\n",
    "    sticking_probabilities: list[float],\n",
    "    interp: bool = False,\n",
    "    fill: bool = False,\n",
    "    monotonic: bool = False,\n",
    ") -> None:\n",
    "    \"\"\"Creates a 3D surface plot of the data in the provided plot axes object.\"\"\"\n",
    "    ax.clear()\n",
    "    xx, yy, zz = to_grid_data(data, sticking_probabilities)\n",
    "    cmap = plt.get_cmap(\"coolwarm\")\n",
    "    if fill:\n",
    "        zz = fill_along_axis(zz, np.isnan(zz), 0)\n",
    "        if monotonic:\n",
    "            mono_mask = ~check_monotonic(zz, axis=0)\n",
    "            zz = fill_along_axis(zz, mono_mask, axis=1)\n",
    "\n",
    "    if interp:\n",
    "        xnew = np.linspace(0, zz.shape[1], 100)\n",
    "        ynew = np.linspace(\n",
    "            np.min(sticking_probabilities), np.max(sticking_probabilities), 100\n",
    "        )\n",
    "        xxnew, yynew = np.meshgrid(xnew, ynew)\n",
    "\n",
    "        zznew = interpolate.griddata(\n",
    "            (xx.ravel(), yy.ravel()),\n",
    "            zz.ravel(),\n",
    "            (xxnew.ravel(), yynew.ravel()),\n",
    "            method=\"linear\",\n",
    "        )\n",
    "        ax.plot_surface(\n",
    "            xxnew,\n",
    "            yynew,\n",
    "            zznew.reshape(xxnew.shape),\n",
    "            linewidth=2,\n",
    "            cmap=cmap,\n",
    "            rstride=1,\n",
    "            cstride=1,\n",
    "            antialiased=True,\n",
    "        )\n",
    "    else:\n",
    "        ax.plot_surface(xx, yy, zz, linewidth=1, cmap=cmap, antialiased=True)\n",
    "\n",
    "    ax.set_xlabel(\"time\")\n",
    "    ax.set_ylabel(\"sticking probability\")\n",
    "    ax.set_zlabel(\"radius\")\n",
    "\n",
    "\n",
    "def plot_data_3d(\n",
    "    pos: np.ndarray,\n",
    "    mapped: np.ndarray,\n",
    "    sticking_probabilities: list[float],\n",
    "    interp: bool = False,\n",
    "    fill: bool = False,\n",
    "    monotonic: bool = False,\n",
    "    figsize: Tuple[float, float] = (10, 5),\n",
    "    selection_callback: Optional[Callable[[int, Axes], None]] = None,\n",
    ") -> Tuple[Figure, Axes]:\n",
    "    \"\"\"Plots the geometry and also creates a 3D surface plot of the data corresponding\n",
    "    to the selected surface point.\"\"\"\n",
    "\n",
    "    point_index = 0\n",
    "\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    ax_selector = fig.add_subplot(121)\n",
    "    ax_3d = fig.add_subplot(122, projection=\"3d\")\n",
    "    fig.subplots_adjust(hspace=0.4)\n",
    "\n",
    "    draw_3d_plot(\n",
    "        ax_3d,\n",
    "        mapped[point_index, :, :],\n",
    "        sticking_probabilities,\n",
    "        interp,\n",
    "        fill,\n",
    "        monotonic,\n",
    "    )\n",
    "\n",
    "    if selection_callback:\n",
    "        selection_callback(point_index, ax_3d)\n",
    "\n",
    "    ax_selector.set_title(\"Geometry\\n(selected: 0)\")\n",
    "    ax_selector.scatter(\n",
    "        pos[:, 0],\n",
    "        pos[:, 1],\n",
    "        color=\"black\",\n",
    "        linewidths=0,\n",
    "        marker=\".\",\n",
    "        picker=True,\n",
    "        pickradius=0.2,\n",
    "    )\n",
    "\n",
    "    scat = ax_selector.scatter(\n",
    "        pos[point_index, 0], pos[point_index, 1], color=\"red\", marker=\"o\"\n",
    "    )\n",
    "\n",
    "    def onpick(event):\n",
    "        if isinstance(event.artist, PathCollection):\n",
    "            point_index = event.ind[0]\n",
    "            colors = np.zeros((len(pos), 3))\n",
    "            colors[point_index, 0] = 1\n",
    "            scat.set_offsets((pos[point_index, 0], pos[point_index, 1]))\n",
    "            ax_selector.set_title(f\"Geometry\\n(selected: {point_index})\")\n",
    "\n",
    "            # Now redraw 3d plot\n",
    "            draw_3d_plot(\n",
    "                ax_3d,\n",
    "                mapped[point_index, :, :],\n",
    "                sticking_probabilities,\n",
    "                interp,\n",
    "                fill,\n",
    "                monotonic,\n",
    "                # fit_function,\n",
    "            )\n",
    "\n",
    "            if selection_callback:\n",
    "                selection_callback(point_index, ax_3d)\n",
    "\n",
    "            fig.canvas.draw_idle()\n",
    "\n",
    "    ax_selector.axis(\"scaled\")\n",
    "    fig.canvas.mpl_connect(\"pick_event\", onpick)\n",
    "    return fig, ax_3d\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and Transforming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all available configurations\n",
    "fnames = listdir(DATA_DIR)\n",
    "configs = map_configs(fnames)\n",
    "\n",
    "config_list = list(configs.items())\n",
    "\n",
    "# Select a particular geometry\n",
    "geometry_index = 57\n",
    "name, sticking = config_list[geometry_index]\n",
    "\n",
    "print(name)\n",
    "trench_diameter = float(name.split(\"_\")[0][1:4])\n",
    "\n",
    "# Load the data of this geometry\n",
    "data_loader = partial(load_data, DATA_DIR)\n",
    "extracted = extract_data(data_loader, name, sticking)\n",
    "data = to_data_tensor(extracted, STICKING_PROBABILITIES)\n",
    "viewfactor_data = to_data_tensor(\n",
    "    extract_data(data_loader, name, [\"s1000\"], prefix=\"viewfactor_\"),\n",
    "    STICKING_PROBABILITIES,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deviation_data = np.zeros_like(data)\n",
    "for i in range(data.shape[1]):\n",
    "    deviation_data[:, i, :] = data[:, i, :] - viewfactor_data[:, 0, :]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extend the dataset with the expected conformal thickness data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_data = np.zeros((data.shape[0], data.shape[1] + 1, data.shape[2]))\n",
    "expanded_data[:, :-1, :] = data.copy()\n",
    "y = np.where(extracted.pos[:, 1] > 0, extracted.pos[:, 1], 0)\n",
    "time = np.arange(data.shape[2])\n",
    "\n",
    "expanded_data[:, -1, :] = np.outer(\n",
    "    np.ones(data.shape[0]),\n",
    "    time,\n",
    ")\n",
    "\n",
    "expanded_data[:, -1, :] = expanded_data[:, -1, :] - np.outer(y, np.ones(data.shape[2]))\n",
    "\n",
    "expanded_data[:, -1, :] = np.where(\n",
    "    expanded_data[:, -1, :] <= trench_diameter / 2,\n",
    "    expanded_data[:, -1, :],\n",
    "    trench_diameter / 2,\n",
    ")\n",
    "\n",
    "expanded_sticking_probabilities = STICKING_PROBABILITIES + [0.0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_index = 300\n",
    "fig, _ = plot_data_2d(\n",
    "    data,\n",
    "    STICKING_PROBABILITIES,\n",
    "    point_index=point_index,\n",
    "    normalize=False,\n",
    "    log=False,\n",
    ")\n",
    "fig, _ = plot_data_2d(\n",
    "    viewfactor_data,\n",
    "    STICKING_PROBABILITIES,\n",
    "    point_index=point_index,\n",
    "    normalize=False,\n",
    "    log=False,\n",
    ")\n",
    "fig, _ = plot_data_2d(\n",
    "    deviation_data,\n",
    "    STICKING_PROBABILITIES,\n",
    "    point_index=point_index,\n",
    "    normalize=False,\n",
    "    log=False,\n",
    ")\n",
    "\n",
    "fig, _ = plot_data_2d(\n",
    "    expanded_data,\n",
    "    expanded_sticking_probabilities,\n",
    "    point_index=point_index,\n",
    "    normalize=False,\n",
    "    log=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3D Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_data_3d(\n",
    "    extracted.pos,\n",
    "    data,\n",
    "    STICKING_PROBABILITIES,\n",
    "    interp=False,\n",
    "    fill=True,\n",
    "    monotonic=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extended dataset (+conformal deposition thickness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_data_3d(\n",
    "    extracted.pos,\n",
    "    expanded_data,\n",
    "    expanded_sticking_probabilities,\n",
    "    interp=False,\n",
    "    fill=True,\n",
    "    monotonic=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Curve Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(\n",
    "    data: np.ndarray,\n",
    "    sticking_probabilities: list[float],\n",
    ") -> None:\n",
    "    def fun(\n",
    "        X: Union[np.ndarray, Tuple[np.ndarray, np.ndarray]],\n",
    "        a: float,\n",
    "        b: float,\n",
    "        c: float,\n",
    "        d: float,\n",
    "        e: float,\n",
    "        f: float,\n",
    "        g: float,\n",
    "    ) -> np.ndarray:\n",
    "        # Normalize and reshape the inputs\n",
    "        x = X[0]  # / 50\n",
    "        y = 1 - X[1]\n",
    "\n",
    "        return a * np.tanh(b * x * (c + d * y)) * (e + f * y**2 + g * y**4)\n",
    "\n",
    "    def fit_surface(\n",
    "        x: np.ndarray,\n",
    "        y: np.ndarray,\n",
    "        a: float,\n",
    "        b: float,\n",
    "        c: float,\n",
    "        d: float,\n",
    "        e: float,\n",
    "        f: float,\n",
    "        g: float,\n",
    "    ) -> np.ndarray:\n",
    "        \"\"\"x: time, y: sp\"\"\"\n",
    "        t = fun((x, y), a, b, c, d, e, f, g)\n",
    "        return t\n",
    "\n",
    "    def callback(point_index: int, ax: Axes) -> None:\n",
    "        x, y, z = to_grid_data(data[point_index, :, :], sticking_probabilities)\n",
    "        z = fill_along_axis(z, np.isnan(z))\n",
    "        mono_mask = ~check_monotonic(z, axis=0)\n",
    "        z = fill_along_axis(z, mono_mask, axis=1)\n",
    "\n",
    "        popt, pcov = curve_fit(fun, (x.ravel(), y.ravel()), z.ravel())\n",
    "        print(popt)\n",
    "\n",
    "        xnew = np.linspace(0, z.shape[1], 100)\n",
    "        ynew = np.linspace(\n",
    "            np.min(sticking_probabilities), np.max(sticking_probabilities), 100\n",
    "        )\n",
    "        xxnew, yynew = np.meshgrid(xnew, ynew)\n",
    "        zznew = fit_surface(xxnew.ravel(), yynew.ravel(), *popt)\n",
    "        ax.plot_surface(\n",
    "            xxnew,\n",
    "            yynew,\n",
    "            zznew.reshape(xxnew.shape),\n",
    "            linewidth=1,\n",
    "            antialiased=True,\n",
    "        )\n",
    "\n",
    "    plot_data_3d(\n",
    "        extracted.pos,\n",
    "        data,\n",
    "        sticking_probabilities,\n",
    "        interp=False,\n",
    "        fill=True,\n",
    "        monotonic=True,\n",
    "        selection_callback=callback,\n",
    "    )\n",
    "\n",
    "\n",
    "optimize(data, STICKING_PROBABILITIES)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

