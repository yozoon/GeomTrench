{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "import gzip\n",
    "from dataclasses import dataclass\n",
    "from functools import partial\n",
    "from os import listdir, path\n",
    "from typing import Callable, Optional, SupportsFloat, Tuple, Union\n",
    "\n",
    "import msgpack\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.axes import Axes\n",
    "from matplotlib.figure import Figure\n",
    "from scipy import interpolate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STICKING_PROBABILITIES = [1.0, 0.8, 0.6, 0.4, 0.2, 0.1]\n",
    "DATA_DIR = \"/run/media/life/barry/ViennaTools/spherical\"\n",
    "fnames = listdir(DATA_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataLoadingFunction = Callable[[str], dict]\n",
    "NumpyOrFloat = Union[float, np.ndarray]\n",
    "\n",
    "\n",
    "@dataclass(frozen=True, slots=True)\n",
    "class ThicknessData:\n",
    "    thickness: list[list[np.ndarray]]\n",
    "    sticking_probabilities: list[float]\n",
    "    max_times: list[int]\n",
    "    num_points: int\n",
    "\n",
    "\n",
    "def map_configs(fnames: list[str]) -> dict[str, list[str]]:\n",
    "    configs = {}\n",
    "    for fname in fnames:\n",
    "        sticking, geom = fname[:5], fname[6:]\n",
    "        if not geom in configs:\n",
    "            configs[geom] = []\n",
    "        configs[geom].append(sticking)\n",
    "    return configs\n",
    "\n",
    "\n",
    "def load_data(data_dir: str, filename: str) -> dict:\n",
    "    with gzip.open(path.join(data_dir, filename)) as gz:\n",
    "        data = msgpack.unpack(gz, use_list=False, raw=False)\n",
    "    return data[\"nodes\"]\n",
    "\n",
    "\n",
    "def extract_data(\n",
    "    loader: DataLoadingFunction, name: str, sticking: list[str]\n",
    ") -> ThicknessData:\n",
    "    data_list: list[list[np.ndarray]] = []\n",
    "    sticking_probabilities: list[float] = []\n",
    "    max_times: list[int] = []\n",
    "    num_points: list[int] = []\n",
    "    for ps in sticking:\n",
    "        node_data = loader(f\"{ps}_{name}\")\n",
    "        labels = [s for s in node_data if s.startswith(\"extracted_\")]\n",
    "        data_list.append([np.array(node_data[l]) for l in labels])\n",
    "        sticking_probabilities.append(float(ps[1:]) / 1000)\n",
    "        max_times.append(len(labels))\n",
    "        num_points.extend([d.shape[0] for d in data_list[-1]])\n",
    "\n",
    "    # Ensure that the number of nodes is the same for all data\n",
    "    assert np.all(np.array(num_points) == num_points[0])\n",
    "\n",
    "    # Construct the data container instance\n",
    "    return ThicknessData(\n",
    "        thickness=data_list,\n",
    "        sticking_probabilities=sticking_probabilities,\n",
    "        max_times=max_times,\n",
    "        num_points=num_points[0],\n",
    "    )\n",
    "\n",
    "\n",
    "def to_data_tensor(data: ThicknessData) -> np.ndarray:\n",
    "    mapped = np.zeros((data.num_points, len(STICKING_PROBABILITIES), 49))\n",
    "    for i, s in enumerate(STICKING_PROBABILITIES):\n",
    "        # First, determine the index\n",
    "        data_index = 0\n",
    "        for sp in data.sticking_probabilities:\n",
    "            if sp == s:\n",
    "                break\n",
    "            data_index = data_index + 1\n",
    "        else:\n",
    "            print(\"Sticking coefficient not found!\")\n",
    "            continue\n",
    "        mapped[:, i, : data.max_times[data_index]] = np.array(\n",
    "            data.thickness[data_index]\n",
    "        ).T\n",
    "    return mapped\n",
    "\n",
    "\n",
    "def plot_data(\n",
    "    mapped: np.ndarray,\n",
    "    sticking_probabilities: list[float],\n",
    "    point_index: int,\n",
    "    normalize: bool = False,\n",
    "    log: bool = False,\n",
    ") -> None:\n",
    "    _, ax = plt.subplots(nrows=1, ncols=2, squeeze=False, figsize=(10, 4))\n",
    "    if normalize:\n",
    "        for i, r in enumerate(np.moveaxis(mapped[point_index, :, :], 0, 1)):\n",
    "            ax[0, 0].plot(\n",
    "                sticking_probabilities,\n",
    "                np.where(r != 0, r / (i + 1), np.nan),\n",
    "                marker=\"x\",\n",
    "            )\n",
    "\n",
    "        for i, r in enumerate(np.moveaxis(mapped[point_index, :, :], 0, 0)):\n",
    "            ax[0, 1].plot(\n",
    "                np.where(r != 0, r / (1 + np.arange(49)), np.nan),\n",
    "                marker=\"x\",\n",
    "                label=sticking_probabilities[i],\n",
    "            )\n",
    "    else:\n",
    "        for i, r in enumerate(np.moveaxis(mapped[point_index, :, :], 0, 1)):\n",
    "            ax[0, 0].plot(\n",
    "                sticking_probabilities, np.where(r != 0, r, np.nan), marker=\"x\"\n",
    "            )\n",
    "\n",
    "        for i, r in enumerate(np.moveaxis(mapped[point_index, :, :], 0, 0)):\n",
    "            ax[0, 1].plot(\n",
    "                np.where(r != 0, r, np.nan),\n",
    "                marker=\"x\",\n",
    "                label=sticking_probabilities[i],\n",
    "            )\n",
    "\n",
    "    ax[0, 0].grid(which=\"both\")\n",
    "    ax[0, 0].set_xlabel(\"sticking probability\")\n",
    "    ax[0, 0].set_ylabel(\"radius\")\n",
    "    ax[0, 1].set_xlabel(\"time\")\n",
    "    ax[0, 1].set_ylabel(\"radius\")\n",
    "    ax[0, 1].grid(which=\"both\")\n",
    "\n",
    "    if log:\n",
    "        ax[0, 0].set_yscale(\"log\")\n",
    "        ax[0, 1].set_yscale(\"log\")\n",
    "    ax[0, 1].legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def to_grid_data(\n",
    "    z: np.ndarray,\n",
    "    sticking_probabilities: list[float],\n",
    ") -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "    \"\"\"Converts the provided data to\"\"\"\n",
    "    y = sticking_probabilities\n",
    "    x = np.arange(z.shape[1])\n",
    "    xx, yy = np.meshgrid(x, y)\n",
    "    zz = np.where(z > 0, z, np.nan)\n",
    "    return xx, yy, zz\n",
    "\n",
    "\n",
    "def plot_data_3d(\n",
    "    mapped: np.ndarray,\n",
    "    sticking_probabilities: list[float],\n",
    "    point_index: int,\n",
    "    interp: bool = False,\n",
    "    fill: bool = False,\n",
    "    fit_function: Optional[\n",
    "        Callable[\n",
    "            [NumpyOrFloat, NumpyOrFloat],\n",
    "            NumpyOrFloat,\n",
    "        ]\n",
    "    ] = None,\n",
    ") -> Tuple[Figure, Axes]:\n",
    "    \"\"\"Creates a 3D surface plot of the provided data\"\"\"\n",
    "    xx, yy, zz = to_grid_data(mapped[point_index, :, :], sticking_probabilities)\n",
    "\n",
    "    cmap = plt.get_cmap(\"coolwarm\")\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(projection=\"3d\")\n",
    "\n",
    "    if fill:\n",
    "        zz = fill_along_axis(zz, np.isnan(zz), 0)\n",
    "\n",
    "    if interp:\n",
    "        xnew = np.linspace(0, zz.shape[1], 100)\n",
    "        ynew = np.linspace(\n",
    "            np.min(sticking_probabilities), np.max(sticking_probabilities), 100\n",
    "        )\n",
    "        xxnew, yynew = np.meshgrid(xnew, ynew)\n",
    "\n",
    "        zznew = interpolate.griddata(\n",
    "            (xx.ravel(), yy.ravel()),\n",
    "            zz.ravel(),\n",
    "            (xxnew.ravel(), yynew.ravel()),\n",
    "            method=\"linear\",\n",
    "        )\n",
    "        ax.plot_surface(\n",
    "            xxnew,\n",
    "            yynew,\n",
    "            zznew.reshape(xxnew.shape),\n",
    "            linewidth=2,\n",
    "            cmap=cmap,\n",
    "            rstride=1,\n",
    "            cstride=1,\n",
    "            antialiased=True,\n",
    "        )\n",
    "    else:\n",
    "        ax.plot_surface(xx, yy, zz, linewidth=1, cmap=cmap, antialiased=True)\n",
    "        # np.save(\"data.npy\", (xx, yy, zz))\n",
    "\n",
    "    if fit_function:\n",
    "        xnew = np.linspace(0, zz.shape[1], 100)\n",
    "        ynew = np.linspace(\n",
    "            np.min(sticking_probabilities), np.max(sticking_probabilities), 100\n",
    "        )\n",
    "        xxnew, yynew = np.meshgrid(xnew, ynew)\n",
    "        zznew = fit_function(xxnew.ravel(), yynew.ravel())\n",
    "        ax.plot_surface(\n",
    "            xxnew,\n",
    "            yynew,\n",
    "            zznew.reshape(xxnew.shape),\n",
    "            linewidth=1,\n",
    "            # cmap=cmap,\n",
    "            antialiased=True,\n",
    "        )\n",
    "\n",
    "    ax.set_xlabel(\"time\")\n",
    "    ax.set_ylabel(\"sticking probability\")\n",
    "    ax.set_zlabel(\"radius\")\n",
    "\n",
    "    return fig, ax\n",
    "\n",
    "\n",
    "data_loader = partial(load_data, DATA_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = map_configs(fnames)\n",
    "\n",
    "config_list = list(configs.items())\n",
    "\n",
    "name, sticking = config_list[12]\n",
    "\n",
    "print(name)\n",
    "mapped = to_data_tensor(extract_data(data_loader, name, sticking))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data(mapped, STICKING_PROBABILITIES, 100, normalize=False, log=False)\n",
    "plot_data(mapped, STICKING_PROBABILITIES, 5, normalize=True, log=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fun(\n",
    "    X: Union[np.ndarray, Tuple[NumpyOrFloat, NumpyOrFloat]],\n",
    "    a: float,\n",
    "    b: float,\n",
    "    c: float,\n",
    "    d: float,\n",
    "    e: float,\n",
    "    f: float,\n",
    "    g: float,\n",
    ") -> NumpyOrFloat:\n",
    "    x = X[0] / 50\n",
    "    y = 1 - X[1]\n",
    "    return a * np.tanh(b * x * (c + d * y)) * (e + f * y**2 + g * y**4)\n",
    "\n",
    "\n",
    "def fit_surface(\n",
    "    x: NumpyOrFloat,\n",
    "    y: NumpyOrFloat,\n",
    "    a: float,\n",
    "    b: float,\n",
    "    c: float,\n",
    "    d: float,\n",
    "    e: float,\n",
    "    f: float,\n",
    "    g: float,\n",
    ") -> NumpyOrFloat:\n",
    "    \"\"\"x: time, y: sp\"\"\"\n",
    "    # x = x / 50\n",
    "    # y = 1 - y\n",
    "    # return a * np.tanh(b * x * (c + d * y)) * (e + f * y**2 + g * y**4)\n",
    "    t = fun((x, y), a, b, c, d, e, f, g)\n",
    "    return t\n",
    "\n",
    "\n",
    "fs = partial(fit_surface, a=7.7, b=5, c=0.5, d=0.5, e=1, f=0, g=1)\n",
    "\n",
    "fig, ax = plot_data_3d(\n",
    "    mapped,\n",
    "    STICKING_PROBABILITIES,\n",
    "    1000,\n",
    "    interp=False,\n",
    "    fill=True,\n",
    "    # fit_function=fs,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit\n",
    "\n",
    "\n",
    "def optimize(point_index: int):\n",
    "    x, y, z = to_grid_data(mapped[point_index, :, :], STICKING_PROBABILITIES)\n",
    "    z = fill_along_axis(z)\n",
    "\n",
    "    popt, pcov = curve_fit(fun, (x.ravel(), y.ravel()), z.ravel())\n",
    "    print(popt)\n",
    "\n",
    "    fs = partial(\n",
    "        fit_surface,\n",
    "        a=popt[0],\n",
    "        b=popt[1],\n",
    "        c=popt[2],\n",
    "        d=popt[3],\n",
    "        e=popt[4],\n",
    "        f=popt[5],\n",
    "        g=popt[6],\n",
    "    )\n",
    "\n",
    "    plot_data_3d(\n",
    "        mapped,\n",
    "        STICKING_PROBABILITIES,\n",
    "        point_index,\n",
    "        interp=False,\n",
    "        fill=True,\n",
    "        fit_function=fs,\n",
    "    )\n",
    "\n",
    "\n",
    "optimize(100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_along_axis(\n",
    "    x: np.ndarray,\n",
    "    mask: np.ndarray,\n",
    "    axis: int = 0,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"Fills values of multidimensional array where mask is True using\n",
    "    (linear) interpolation along one axis.\"\"\"\n",
    "    x = x.copy()\n",
    "    for (sequence, ma) in zip(np.moveaxis(x, 0, axis), np.moveaxis(mask, 0, axis)):\n",
    "        if ma.sum() != 0 and (~ma).sum():\n",
    "            sequence[ma] = np.interp(\n",
    "                np.flatnonzero(ma), np.flatnonzero(~ma), sequence[~ma]\n",
    "            )\n",
    "    return x\n",
    "\n",
    "\n",
    "def check_monotonic(\n",
    "    x: np.ndarray,\n",
    "    axis: int = 0,\n",
    "    eps: float = 0.1,\n",
    "    increasing: bool = True,\n",
    "):\n",
    "    \"\"\"Checks if the provided array is monotonically increasing or decreasing along the provided axis\"\"\"\n",
    "    assert axis < len(x.shape)\n",
    "    if increasing:\n",
    "        monotonic = np.diff(x, 1, axis=axis, prepend=0) > -eps\n",
    "    else:\n",
    "        monotonic = np.diff(x, 1, axis=axis, append=0) > eps\n",
    "    return monotonic\n",
    "\n",
    "\n",
    "def to_monotonic(x, sticking_probabilities):\n",
    "    xx, yy, zz = to_grid_data(x, sticking_probabilities)\n",
    "    zz = fill_along_axis(zz, np.isnan(zz), 0)\n",
    "\n",
    "    mono_mask = ~check_monotonic(zz, axis=0)\n",
    "\n",
    "    zz = fill_along_axis(zz, mono_mask, axis=1)\n",
    "\n",
    "    # Plotting\n",
    "    _, ax = plt.subplots(1, 1)\n",
    "    ax.contourf(xx, yy, zz)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "to_monotonic(mapped[1500, :, :], STICKING_PROBABILITIES)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Genetic Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gplearn.genetic import SymbolicRegressor\n",
    "\n",
    "\n",
    "def regress_gp():\n",
    "    x, y, z = np.load(\"data.npy\")\n",
    "    X = np.vstack([x.flatten(), y.flatten()]).T\n",
    "    Y = z.flatten()\n",
    "    print(X.shape)\n",
    "    print(Y.shape)\n",
    "    est = SymbolicRegressor(\n",
    "        population_size=5000,\n",
    "        generations=50,\n",
    "        stopping_criteria=0.01,\n",
    "        p_crossover=0.7,\n",
    "        p_subtree_mutation=0.1,\n",
    "        p_hoist_mutation=0.05,\n",
    "        p_point_mutation=0.1,\n",
    "        max_samples=0.9,\n",
    "        verbose=1,\n",
    "        parsimony_coefficient=0.01,\n",
    "        random_state=0,\n",
    "    )\n",
    "    est.fit(X, Y)\n",
    "    return est\n",
    "\n",
    "\n",
    "from pysr import PySRRegressor\n",
    "\n",
    "\n",
    "def regress_pysr():\n",
    "    x, y, z = np.load(\"data.npy\")\n",
    "    X = np.vstack([x.flatten(), y.flatten()]).T\n",
    "    Y = z.flatten()\n",
    "\n",
    "    model = PySRRegressor(\n",
    "        model_selection=\"best\",  # Result is mix of simplicity+accuracy\n",
    "        niterations=40,\n",
    "        binary_operators=[\"+\", \"*\"],\n",
    "        unary_operators=[\n",
    "            \"exp\",\n",
    "            \"sigm(x) = 1 / (1+exp(-x))\",\n",
    "            \"inv(x) = 1/x\",\n",
    "            # ^ Custom operator (julia syntax)\n",
    "        ],\n",
    "        extra_sympy_mappings={\n",
    "            \"inv\": lambda x: 1 / x,\n",
    "            \"sigm\": lambda x: 1 / (1 + np.exp(-x)),\n",
    "        },\n",
    "        # ^ Define operator for SymPy as well\n",
    "        # loss=\"loss(x, y) = (x - y)^2\",\n",
    "        # ^ Custom loss function (julia syntax)\n",
    "    )\n",
    "    model.fit(X, Y)\n",
    "    return model\n",
    "\n",
    "\n",
    "est = regress_pysr()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_est(\n",
    "    est: SymbolicRegressor,\n",
    "    mapped: np.ndarray,\n",
    "    sticking_probabilities: list[float],\n",
    "    point_index: int,\n",
    ") -> None:\n",
    "    cmap = plt.get_cmap(\"coolwarm\")\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(projection=\"3d\")\n",
    "    z = mapped[point_index, :, :]\n",
    "\n",
    "    x = np.linspace(0, z.shape[1], 100)\n",
    "    y = np.linspace(np.min(sticking_probabilities), np.max(sticking_probabilities), 100)\n",
    "    xx, yy = np.meshgrid(x, y)\n",
    "\n",
    "    X = np.vstack([xx.flatten(), yy.flatten()]).T\n",
    "\n",
    "    zz = est.predict(X)\n",
    "\n",
    "    ax.plot_surface(\n",
    "        xx,\n",
    "        yy,\n",
    "        zz.reshape(xx.shape),\n",
    "        linewidth=2,\n",
    "        cmap=cmap,\n",
    "        rstride=1,\n",
    "        cstride=1,\n",
    "        antialiased=True,\n",
    "    )\n",
    "\n",
    "plot_est(est, mapped, STICKING_PROBABILITIES, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(est._program)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

